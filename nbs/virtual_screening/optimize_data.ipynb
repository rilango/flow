{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/')\n",
    "\n",
    "import sqlite3\n",
    "import mols2grid\n",
    "import importlib\n",
    "import pickle\n",
    "import itertools\n",
    "import concurrent\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cuml\n",
    "import cupy as cp\n",
    "\n",
    "from functools import partial\n",
    "from subprocess import run\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, QED, Descriptors, Lipinski, rdDistGeom, rdmolfiles\n",
    "\n",
    "from flow.pipeline.screening.pose_generate import score_molecule, generate_conformers\n",
    "from flow.utils.megamolbart import smiles_to_embedding, embedding_to_smiles, sample\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Code to disable rdkit errors and warning\n",
    "import rdkit.rdBase as rkrb\n",
    "import rdkit.RDLogger as rkl\n",
    "\n",
    "log = rkl.logger()\n",
    "log.setLevel(rkl.ERROR)\n",
    "rkrb.DisableLog('rdApp.error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = '/content/28b0e566-a15a-11ec-83ca-7de881115940'\n",
    "\n",
    "receptor_file = f'{workspace}/inputs/rec.pdbqt'\n",
    "score_config = f'{workspace}/inputs/config'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Please start MegaMolBART service before this cell\n",
    "```\n",
    "docker-compose --env-file .env\\\n",
    "                -f support/docker/megamolbart/docker-compose.yml\\\n",
    "                up  --scale megamolbart=2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "db_url = '/data/chembl.db'\n",
    "conn = sqlite3.connect(db_url, uri=True)\n",
    "generation = 0\n",
    "\n",
    "df = pd.read_sql(\n",
    "    '''\n",
    "     SELECT canonical_smiles as smiles\n",
    "     FROM compound_structures order by random()\n",
    "     LIMIT 100\n",
    "     ''', \n",
    "     con=conn)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "x0_smis = []\n",
    "x0_dims = []\n",
    "x0_embs = []\n",
    "y0_scrs = []\n",
    "\n",
    "x1_smis = []\n",
    "x1_dims = []\n",
    "x1_embs = []\n",
    "y1_scrs = []\n",
    "\n",
    "for smi in df['smiles'].tolist():\n",
    "    embs = None\n",
    "    while True:\n",
    "        try:\n",
    "            embs = sample(smi,\n",
    "                          num_sample=1, \n",
    "                          padding_size=512,\n",
    "                          service_port='localhost:50052')\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            break\n",
    "        if Chem.MolFromSmiles(embs[1]['smiles']) is None or embs[0]['smiles'] == embs[1]['smiles']:\n",
    "            # print(f'{x1_smi} is invalid or same as input {x0_smi}')\n",
    "            continue\n",
    "\n",
    "        emb = embs[0]['embedding']\n",
    "        x0_embs.append(cp.reshape(cp.array(emb.embedding), emb.dim).squeeze())\n",
    "        x0_dims.append(list(emb.dim))\n",
    "        x0_smis.append(embs[0]['smiles'])\n",
    "\n",
    "        emb = embs[1]['embedding']\n",
    "        x1_embs.append(cp.reshape(cp.array(emb.embedding), emb.dim).squeeze())\n",
    "        x1_dims.append(list(emb.dim))\n",
    "        x1_smis.append(embs[1]['smiles'])\n",
    "        break\n",
    "    \n",
    "x0_smis, x1_smis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for smi in x0_smis:\n",
    "    min_score, score_model = score_molecule(smi,\n",
    "                                            receptor_file=receptor_file,\n",
    "                                            score_config=score_config,\n",
    "                                            conformer_dir='/tmp')\n",
    "    y0_scrs.append(min_score)\n",
    "    \n",
    "for smi in x1_smis:\n",
    "    min_score, score_model = score_molecule(smi,\n",
    "                                            receptor_file=receptor_file,\n",
    "                                            score_config=score_config,\n",
    "                                            conformer_dir='/tmp')\n",
    "    y1_scrs.append(min_score)\n",
    "y0_scrs, y1_scrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# db_url = f'{workspace}/common.sqlite3'\n",
    "# conn = sqlite3.connect(db_url, uri=True)\n",
    "# df = pd.read_sql(\n",
    "#     '''\n",
    "#     Select smiles, embedding, embedding_dim, score from generated_smiles\n",
    "#     LIMIT 100\n",
    "#     ''', \n",
    "#     con=conn)\n",
    "\n",
    "# for i in range(df.shape[0]):\n",
    "#     dim = pickle.loads(df.embedding_dim[i])\n",
    "#     x0_smi = df.smiles[i]\n",
    "#     x0_smis.append(x0_smi)\n",
    "#     x0_dims.append(dim)\n",
    "#     x0_embs.append(cp.reshape(cp.array(pickle.loads(df.embedding[i])), dim))\n",
    "#     y0_scrs.append(df.score[i])\n",
    "    \n",
    "#     while(True):\n",
    "#         x1_samples = sample(x0_smi, service_port='localhost:50052', num_sample=1)\n",
    "#         x1_sample = x1_samples[1]\n",
    "#         x1_smi = x1_sample['smiles']\n",
    "        \n",
    "#         #TODO: This could lead to an infinite loop\n",
    "#         if Chem.MolFromSmiles(x1_smi) is None or x0_smi == x1_smi:\n",
    "#             # print(f'{x1_smi} is invalid or same as input {x0_smi}')\n",
    "#             continue\n",
    "\n",
    "#         dim = x1_sample['embedding'].dim\n",
    "#         x1_smis.append(x1_smi)\n",
    "#         x1_dims.append(cp.array(dim))\n",
    "#         x1_embs.append(cp.reshape(cp.array(x1_sample['embedding'].embedding), dim))\n",
    "#         break\n",
    "#     # y1_scrs.append(df.score[i])\n",
    "\n",
    "# # smi, emb, dim, scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape embedding to equal shape\n",
    "# import itertools\n",
    "# max_size = x1_embs[0].shape\n",
    "# for emb in x1_embs:\n",
    "#     print(emb.shape)\n",
    "#     if max_size[0] < emb.shape[0]:\n",
    "#         max_size = emb.shape\n",
    "\n",
    "# for i in range(len(x1_embs)):\n",
    "#     emb = x0_embs[i]\n",
    "#     dim = x0_dims[i]\n",
    "#     smi = x0_smis[i]\n",
    "#     mask = itertools.repeat(False, max_size[0])\n",
    "#     emb = cp.resize(emb, max_size)\n",
    "#     flattened = emb.flatten().tolist()\n",
    "#     re_smi = embedding_to_smiles(flattened, max_size, mask, service_port='localhost:50052')\n",
    "#     print(type(flattened), dim, len(smi), smi, re_smi)\n",
    "    \n",
    "# max_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the matching input and sample pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from functools import partial\n",
    "# import concurrent\n",
    "\n",
    "# receptor_file = f'{workspace}/inputs/rec.pdbqt'\n",
    "# score_config = f'{workspace}/inputs/config'\n",
    "\n",
    "# partial_func = partial(score_molecule,\n",
    "#                        receptor_file=receptor_file,\n",
    "#                        score_config=score_config,\n",
    "#                        conformer_dir='/tmp')\n",
    "\n",
    "# with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "#     futures = {executor.submit(partial_func, smi): smi for smi in x1_smis}\n",
    "\n",
    "#     y1_map = dict(zip(x1_smis, itertools.repeat(None, len(x1_smis))))\n",
    "#     for future in concurrent.futures.as_completed(futures):\n",
    "#         min_score, score_model = future.result()\n",
    "#         y1_map[futures[future]] = min_score\n",
    "#     y1_scrs = list(y1_map.values())\n",
    "# y1_scrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict({\n",
    "    'x0_smis': x0_smis,\n",
    "    'x0_dims': x0_dims,\n",
    "    'x0_embs': x0_embs,\n",
    "    'y0_scrs': y0_scrs,\n",
    "    'x1_smis': x1_smis,\n",
    "    'x1_dims': x1_dims,\n",
    "    'x1_embs': x1_embs,\n",
    "    'y1_scrs': y1_scrs\n",
    "    })\n",
    "\n",
    "with open('/workspace/test_data.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/workspace/test_data.pkl', 'rb') as file:\n",
    "    # A new file will be created\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x1_dims)):\n",
    "    x1_dims[i] = list(x1_dims[i])\n",
    "\n",
    "    \n",
    "for i in range(len(x0_dims)):\n",
    "    x0_dims[i] = list(x0_dims[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
